<d-article>
{% include contents.html %}
{% include nextPrev.html %}
<h2 id='patterns-and'>Patterns and Textures</h2>
<p></p>
<figure>
<img src='images/zebra.jpg' style='width: 450px'>
<figcaption>A pair of Zebra. Zebra are said to have unique stripes.</figcaption>
</figure>

<p>Zebra stripes consist of a characteristic pattern that practically anybody can both recognize in the wild, and describe - at least to some degree. At the same time, it is said that no two zebras have identical stripes<d-footnote> Perhaps apocryphal, but the authors would wager it true were you to pedantically measure every molecule on the surface of said zebra. Point is - "zebra stripes" - as a concept in human understanding - refers to the general structure of a black and white striped pattern, and not to a specific mapping from location to colour.</d-footnote>. One can then draw the conclusion that evolution has programmed the cells responsible for creating the Zebra pattern to generate a pattern of a certain quality, with certain characteristics, as opposed to programming them with the blueprints for an exact bitmap of the edges and locations of stripes to be moulded to the surface of the Zebra's body. </p>

<p>Patterns and textures are ill-defined concepts. If you were to surprise someone on the street, and ask them to define a pattern, you may expect an answer along the lines of: a pattern, at least in the visual sense, is any repeating set of visual landmarks that lends itself to tiling in some shape or form. But this pseudo definition falls apart rather quickly when looking at patterns and textures that impart a feeling or quality, rather than a specific repeating property. A fuzzy rug, for instance, can be considered a pattern or a texture, but is composed of strands pointing in random directions, with no discernable regularity to the pattern. A standard maze can also be constructed in a way as to be completely non-repeating, but would colloquially still be described as a pattern. What the authors believe is that patterns are often the outputs of processes that may or may not be stochastic in nature, but are often based upon fairly simple rules. </p>

<p>We hope our keen readers have already been convinced of the ability of our differentiable Cellular Automata model to almost perfectly recreate any image when trained with a pixel based loss. If not, we encourage them to peruse our seminal article on Growing Cellular Automata [todo: link to growing-ca + cite].</p>

<p>Now, suppose we instead want to approximate a certain "style" or a pattern, and leave a degree of freedom in terms of the exact pixel values and distribution used to approximate such a pattern. As luck would have it, there has been extensive research on style transfer and feature visualization by constructing input images to excite or constrain certain intermediate layers of neural networks trained on image tasks, with the go-to network for extracting these statistics being the VGG family of image classifiers. For further reference, a good summary of such work is available in <a href='https://distill.pub/2018/differentiable-parameterizations/'>Differentiable Parametrizations</a>. [todo:properly cite+link]</p>

<p>Just as in Differentiable Parametrizations, we can employ the building-block aspect of differentiable models to plug in our Cellular Automata as the parametrization layer for an image we are trying to constrain to a certain style - having the CAs act as the "renderer", so to speak, and having a second network, such as VGG, act as a distinguisher of patterns - providing the gradient necessary to produce a pattern of a certain style.</p>

<p>Let's give this simple experiment a try - processing a pattern of interest through VGG, we pick an intermediate layer which is known to be a good representation of the "styles" involved and note the activations of the neurons. Now, we feedconnect the output of our Cellular Automata tointo VGG and backpropagate into the parameters of the automata.</p>
<p>Immediately notice that they produce coherent patterns in the style of our requested input image, and are able to learn these in very few steps.</p>

<p>[CLICKABLE INTERACTIVE IMAGE GRAPHIC]</p>

<p>What's more interesting and not readily apparent in snapshots of batches is that the patterns are in fact not static. Taking a look at the video below, we see all manners of gradual motion. This is not entirely unexpected - in the definition of our experiments we do not place any constraints onwhich individual pixel values should be - instead we just want the overall output to approximate a pattern we chose through our target image. Given the many convolutional layers in VGG, the network likely does not depend much on the exact spatial placement of the pattern, but rather only onwith its presence.</p>
<h2 id='feature-visualization'>Feature Visualization</h2>

<p></p>
<figure>
<img src='images/butterfly_eye.jpg' style='width: 450px'>
<figcaption>A pair of Zebra. Zebra are said to have unique stripes.</figcaption>
</figure>

<p>Some butterflies have remarkably lifelike eyes on their wings. Evolution has placed these there to trigger a response of fear in potential predators. It is likely that neither the predator nor the butterfly has a concept for what an eye is or does, or even less so any <a href='https://en.wikipedia.org/wiki/Theory_of_mind'>theory of mind</a> regarding each other, but the magic of evolutionary development has nonetheless reached a state where the butterfly ingeniously tricks predators into fearing a harmless bug instead of consuming it. </p>

<p>Even more remarkable is the fact that the individual cells composing the butterfly's wings can self assemble into coherent, beautiful, shapes far larger than an individual cell - indeed a cell is on the order of 1e-...m while the features on the wings will grow to as large as 1e-...m. Communication over this distance implies a self-organization over a distance of millions of cells.</p>

<p>In addition to style transfer -  a common approach to investigating neural networks (cite: OpenAI microscope) is to look at what inhibits or excites individual neurons in a network. Just as neuroscientists and biologists have often treated cells and cell structures and neurons as black-box models to be investigated, measured and reverse-engineered, there is's a large contemporary body of work on doing the same with neural networks. </p>

<p>Luckily, we can explore this idea with minimal effort by simply taking our VGG implementation from before and exploring what happens if we are to generate a CA that excites a given neuron. </p>

<p>[EYE GENERATING CA GRAPHIC]</p>

<p>[TODO: diagram similar to diff param]</p>

<p>We take the output of the CA after a certain number of iterations, and simpy use it as the input for a different network. There is a high-level equ</p>
<h2 id='solitons-lenia'>Solitons, Lenia, and Smoothlife</h2>
<p>The motion of waves propagating through a medium can be described using the "classical" wave equation. </p>

<p>[todo: insert latex wave-eq] </p>

<p>One can imagine waves to come either as a single wave, or as a larger mixture of waves of different frequencies - a phenomenon referred to as a "group" or a "packet". Physical phenomena, however, are rarely as structured and regular as we would like them to be. To describe real-world waves, such as waves in water, light waves propagating, or sound, we have somewhat more complex partial differential equations governing their motion. These waves all share a common property - that waves of different frequencies will travel at different speeds. "Speed" in such a context is a tricky thing to define - however in this case we are referring to the speed of any single given wave - how fast its peak travels in space. When waves of different frequencies have different speeds, groups of waves are no longer cohesive and will experience "dispersion" - the envelope of the group of waves will change shape over time and potentially not remain cohesive. Even in wave groups with dispersive properties, it is possible to find solutions to their partial differential equations where nonlinearities in the propagation and interaction between waves will counteract the dispersive properties of the wave group. This phenomenon, while lacking a strict definition, is called a "soliton" - as it describes a wave packet which exactly retains its shape during propagation.</p>

<p>Recall the idea briefly touched upon in Growing Neural Cellular Automata - that the communicating grid of CAs can be thought of as a finite difference approximation of a partial differential equation in both time and space, with the equation parametrized by a neural network. Several of the patterns we render from DTD, or even in inception, consist of well defined structures such as circles (link polka dot or eyes) or polygons (link bee-hive). We consider such structures to be functionally equivalent to solitons in the world of waves and refer to them as such. Solitons are also used to describe the structures found in "Lenia" by B. Chan - solid, self-maintaining structures occurring as solutions to the continuous approximation to Game of Life.</p>

<p>In the case of pattern generation with CAs, the most curious aspect of the resulting CA is how it tends to find a solution to generating the pattern that is often similar to  a potential physical process that would generate such a pattern. This concept is somewhat ill defined and hard to quantitatively measure, but we will attempt to demonstrate the idea through a number of examples. </p>

<h2 id='interesting-properties'>Interesting properties of solitons and their interactions.</h2>

<ul><li>Solitons in the form of regular circle-like shapes with internal structure are quite common ly observed in the Inception renderings. Two solitons approaching each other too closely may decay. </li>
<li></li>
<li>Solitons can "divide" into two</li>
<li>In textures that are composed of threads or lines, the thread grow in their respective directions and exhibit behaviour where they will join other threads, or grow around them. </li>
<li></li>
<li>Solitons can arrange themselves in a regular pattern, such as a grid or a euclidean tiling of hexagons. They will merge and divide accordingly until they achieve a state of consensus across the whole grid. This is especially visible when </li>
<li></li>
<li></li></ul>
<h2 id='hidden-states'>Hidden states</h2>
<p>There are various ways to visualize these communication channels - but one of them is to add to cells a potential-activated dye - allowing a clear picture of the voltage potential the cell is under with respect to the surrounding substrate. This technique has provided useful insight into the communication patterns within groups of cells - showing both local and nonlocal communication over a variety of time-scales.</p>

<p>As luck would have it - we can do something very similar with our Cellular Automata. Recall that our CA model consists of three visible channels, with the rest being treated as latent channels visible to the update step but excluded from any loss function. . The figure below visualizes the magnitudes of these hidden channels when mapped to intensity in RGB. </p>

<p>We immediately noticed several interesting aspects.</p>

<p>This means the hidden channels can be considered to be "floating" (to borrow a term from circuits) - they are not being pulled to any specific final state or intermediate state and instead converge to some dynamical system assisting the cell fulfill its "true" objective</p>

<p>The flow of gradient back through the CA enters the CA at its final iteration. This suggests that final dynamics of the hidden state must be strongly influenced by the first gradient update it receives "through" this final iteration. Indeed we can consider this to be a dynamical system within a dynamical system. CA back through the preceding iterations gives us a clue as to what aspects of the CA's training may influence what the hidden state dynamical system looks like. </p>

<p>When biological cells communicate with each other, they do so through a multitude of available communication channels. Cells can emit or absorb different ions and proteins, sense physical motion or "stiffness" of other cells or even emit different chemical signals to diffuse over the local substrate (citation needed + cleanup for all these). </p>

<p>Visualization</p>

<ul><li>Hidden state analysis yields some interesting results. For instance - certain anomalies in patterns will only appear after some time (eyes) and you can see distinct activity in the regions where they are about to appear. </li>
<li>Hidden states for automata trained from the same ancestors have similar magnitudes.</li>
<li>Visualization concept:</li><ul>
<li>Show hidden state alongside the the RGB state, and highlight the neural activity in the hidden state with a red circle or "highlight" effect (dark overlay + lightened focus)</li></ul></ul>

<p>References:</p>
<ul><li><a href='http://www.robots.ox.ac.uk/~vgg/publications/2014/Cimpoi14/cimpoi14.pdf'>Describing Textures in the Wild</li></ul>

</d-article>
<d-appendix>

    <d-footnote-list></d-footnote-list>
    <d-citation-list></d-citation-list>
<d-appendix>