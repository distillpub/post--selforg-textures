<d-article>
%% contents.html
<h2 id='patterns-and'>Patterns and Textures</h2>
<p></p>

<p>Zebra stripes have a characteristic pattern anyone can recognize and describe. At the same time it is said that no two zebras have identical stripes. One would then draw the conclusion that evolution has programmed these cells to generate a certain pattern, with certain characteristics, as opposed to programming them with an exact bitmap of stripes to mould the surface of the Zebra’s body. </p>

<p>Patterns and textures in are intriguing visual features in many ways. One may postulate that a pattern is any repeating set of visual landmarks that lends itself to tiling in some shape or form. But this pseudo definition falls apart rather quickly when looking at patterns and textures that impart a feeling or quality, rather than a specific repeating property. A fuzzy rug, for instance, can be considered a pattern or a texture, but is composed of random strands pointing in random directions, with no discernable regularity to the pattern. A standard maze can also be constructed in a way as to be completely non-repeating, but can be still be described as a pattern. </p>

<p>We hope keen readers are convinced of the ability of our CA model to almost perfectly recreate any given image when trained with a pixel based loss - if they not - we encourage them to peruse our seminal article on Growing Cellular Automata.</p>
<p>Now, suppose we instead want them to simply approximate a certain “style” or a pattern, and leave them a degree of freedom in terms of the exact pixel values and distribution used to approximate such a pattern. As luck would have it, there’s been extensive research on style transfer and feature visualization by constructing input images to excite or constrain certain intermediate layers of neural networks trained on image tasks, with the go-to network being VGG. Much of this work is summarized and discussed in <u>Differentiable Parametrizations</u>.</p>

<p>Just as in Differentiable Parametrizations, we can employ the building-block aspect of differentiable models to plug in our Cellular Automata as the parametrization layer for an image we are trying to constrain to a certain style - having the CAs act as the “renderer”, so to speak, and having a second network, such as VGG, act as a distinguisher of patterns - providing the gradient necessary to produce a pattern of a certain style</p>

<p>Let’s give this simple experiment a try - processing a pattern of interest through VGG, we pick an intermediate layer which is known to be a good representation of the “styles” involved and note the activations of the neurons. Now, we connect the output of our Cellular Automata into VGG and backpropagate into the parameters of the automata</p>
<p>Immediately notice that they produce coherent patterns in the style of our requested input image, and are able to learn these in very few steps.</p>

<p>[CLICKABLE INTERACTIVE IMAGE GRAPHIC]</p>

<p>What’s more interesting and not readily apparent in snapshots of batches is that the patterns are in fact not static. Taking a look at the video below, we see all manners of gradual motion. This is not entirely unexpected - in the definition of our experiments we do not place any constraints which individual pixel values should be - instead we just want the overall output to approximate a pattern we chose through our target image. Given the many convolutional layers in VGG, the network likely does not depend much on the exact spatial placement of the pattern, but rather only with its presence.</p>


<h2 id='feature-visualization'>Feature Visualization</h2>

<p>Some (all?) butterflies have remarkably lifelike eyes on their wings. Evolution has placed these there to trigger a response of fear in potential predators. It is likely that neither the predator nor the butterfly has a concept for what an eye is or does, or even less so any <u>theory of mind</u> regarding each other, but the magic of evolutionary development has nonetheless reached a state where the butterfly ingeniously tricks predators into fearing a harmless bug instead of consuming it. </p>

<p>Even more remarkable is the fact that the individual cells composing the butterfly’s wings can self assemble into coherent, beautiful, shapes far larger than an individual cell - indeed a cell is on the order of 1e-...m while the features on the wings will grow to as large as 1e-...m. Communication over this distance implies a self-organization over a distance of millions of cells.</p>

<p>In addition to style transfer -  a common approach to investigating neural networks (cite: OpenAI microscope) is to look at what inhibits or excites individual neurons in a network. Just as neuroscientists and biologists have often treated cells and cell structures and neurons as black-box models to be investigated, measured and reverse-engineered, there’s a large contemporary body of work on doing the same with neural networks. </p>

<p>Luckily, we can explore this idea with minimal effort by simply taking our VGG implementation from before and exploring what happens if we are to generate a CA that excites a given neuron. </p>

<p>[EYE GENERATING CA GRAPHIC]</p>

<h2 id='solitons'>Solitons</h2>
<p>Tasked with re-creating patterns, we see interesting behaviour. </p>

<h2 id='hidden-states'>Hidden states</h2>
<p>There are various ways to visualize these communication channels - but one of them is to add to cells a potential-activated dye - allowing a clear picture of the voltage potential the cell is under with respect to the surrounding substrate. This technique has provided useful insight into the communication patterns within groups of cells - showing both local and nonlocal communication over a variety of time-scales.</p>

<p>As luck would have it - we can do something very similar with our Cellular Automata. Recall that our CA model consists of three visible channels, with the rest being treated as latent channels visible to the update step but excluded from any loss function. . The figure below visualizes the magnitudes of these hidden channels when mapped to intensity in RGB. </p>

<p>We immediately noticed several interesting aspects.</p>

<p>This means the hidden channels can be considered to be “floating” (to borrow a term from circuits) - they are not being pulled to any specific final state or intermediate state and instead converge to some dynamical system assisting the cell fulfill its “true” objective</p>

<p>The flow of gradient back through the CA enters the CA at its final iteration. This suggests that final dynamics of the hidden state must be strongly influenced by the first gradient update it receives “through” this final iteration. Indeed we can consider this to be a dynamical system within a dynamical system. CA back through the preceding iterations gives us a clue as to what aspects of the CA’s training may influence what the hidden state dynamical system looks like. </p>

<p>When biological cells communicate with each other, they do so through a multitude of available communication channels. Cells can emit or absorb different ions and proteins, sense physical motion or “stiffness” of other cells or even emit different chemical signals to diffuse over the local substrate (citation needed + cleanup for all these). </p>

<p>Visualization</p>

<ul><li>Hidden state analysis yields some interesting results. For instance - certain anomalies in patterns will only appear after some time (eyes) and you can see distinct activity in the regions where they are about to appear. </li></ul>
<ul><li>Hidden states for automata trained from the same ancestors have similar magnitudes.</li></ul>
<ul><li>Visualization concept:</li></ul>
<ul><li>Show hidden state alongside the the RGB state, and highlight the neural activity in the hidden state with a red circle or “highlight” effect (dark overlay + lightened focus)</li></ul>

<p>References:</p>
<ul><li><u>Describing Textures in the Wild</u></li></ul>

</d-article>
<d-appendix>

<d-footnote-list></d-footnote-list>
<d-citation-list></d-citation-list>
<d-appendix>