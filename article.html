<d-article>
{% include contents.html %}
{% include nextPrev.html %}


<p>NCAs (Neural Cellular Automata) have been shown to be capable of a diverse set of learned behaviours: from generating stable, regenerating, static images <d-cite key="Mordvintsev_Randazzo_Niklasson_Levin_2020"></d-cite>, to segmenting images <d-cite key="sandler"></d-cite>, and to learning to self-classify shapes <d-cite key="Randazzo_Mordvintsev_Niklasson_Levin_Greydanus_2020"></d-cite>. The inductive prior imposed by using cellular automata is powerful - a system of individual agents running the same learned, simple, rule can solve surprisingly complex tasks, requiring coordination between cells across larger distances. The way they solve these tasks is by necessity massively parallel and inherently degenerate - each cell must be able to take on the role of any other cell - as a result they tend to generalize well to unseen situations. There is a case to be made that the cells learn <i>behaviours</i> - learned, distributed algorithms. </p>

<p>In this work we set out to qualitatively explore how, and what kind of behaviours, a CA will learn. We task the NCA with a loss allowing for a degree of ambiguity and investigate its behaviour. To do this, we use an old trick: employing them as differentiable parameterizations <d-cite key="Mordvintsev2018-dc"></d-cite>.</p>

<h2 id='patterns-textures'>Patterns, textures and physical processes</h2>
<p></p>
<figure>
<img src='images/zebra.jpg' style='width: 450px'>
<figcaption>A pair of Zebra. Zebra are said to have unique stripes.</figcaption>
</figure>

<p>Zebra stripes consist of a characteristic pattern. Ask almost anyone to identify zebra stripes in a set of images, and they&#39;ll have no trouble doing so. Ask them to describe what zebra stripes look like, and they will gladly tell you that they are stripes of varying shape and direction, alternating in black and white. At the same time, it is said that no two zebra have identical stripes<d-footnote> Perhaps apocryphal, but we would wager it true were you to pedantically measure every molecule on the surface of said zebra. Point is - "zebra stripes" as a concept in human understanding refers to the general structure of a black and white striped pattern, and not to a specific mapping from location to colour.</d-footnote>. One can then draw the conclusion that evolution has programmed the cells responsible for creating the Zebra pattern to generate a pattern of a certain quality, with certain characteristics, as opposed to programming them with the blueprints for an exact bitmap of the edges and locations of stripes to be moulded to the surface of the Zebra's body. </p>

<p>Patterns and textures themselves, as terms, are ill-defined concepts. The Cambridge English Dictionary defines a pattern as &quot;any regularly repeated arrangement, especially a design made from repeated lines, shapes, or colours on a surface&quot;. This is all good and well, but this pseudo definition falls apart rather quickly when looking at patterns and textures that impart a feeling or quality, rather than a specific repeating property. A coloured fuzzy rug, for instance, can be considered a pattern or a texture, but is composed of strands pointing in random directions with random colour, and no discernable regularity to the pattern. The famous Penrose tilings do not repeat (specifically - they are not translationally invariant), but show them to anyone and they&#39;ll describe them as a pattern or a texture. We believe that many patterns, at least in nature, are often the outputs of locally interacting processes that may or may not be stochastic in nature, but are often based upon fairly simple rules. There has been extensive work studying models which can give rise to such patterns, with most work based on Turing&#39;s seminal paper on morphogenesis. <d-cite key="Turing_1990"></d-cite></p>

<p>To see how NCAs fare with recreating patterns, our first experiment is to investigate their  behaviour when tasked with a classic style-transfer task. Below we summarize the experimental setup. </p>

<p>As in Differentiable Parametrizations, we employ the building-block aspect of differentiable models to use the Cellular Automata as the parametrization layer for an image we are trying to &quot;stylize&quot;. In this case, instead of having an image be re-styled in a new way, our starting point is completely unconstrained - it&#39;s the raw output of an NCA with random weights. We effectively use the NCAs as the "renderer", so to speak, and VGG as a distinguisher of patterns - providing the gradient necessary to produce a pattern of a certain style.</p>
<h3>NCAs as pattern generators</h3>
<h4>Model: </h4>
<p></p>
<figure>
<img src='images/model.jpg' style='width: 450px'>
<figcaption>Texture NCA model.</figcaption>
</figure>

<p>We build on the Growing CA NCA model <d-cite key="growing-ca"></d-cite>, complete with built-in quantization of weights, and the batch pool mechanism to approximate long-term training. One alteration is the addition of a discretized laplacian filter in addition to the sobel operator filter during the <strong>perception</strong> stage. The motivation is that certain processes, such as those in the reaction-diffusion family, are functions of the laplacian and we wish for our neural network to have the ability to approximate such functions. Qualitatively, this led to better convergence and smoother patterns. </p>
<h4>Loss function: </h4>
<p>Differentiable Parametrizations <d-cite key="Mordvintsev_Pezzotti_Schubert_Olah_2018"></d-cite> explains why VGG is the most commonly used network for implementing style-transfer. We use VGG for the same reason. We start with a template image, $\vec{x}$, we feed into VGG. We then collect statistics from certain layers (<i>block{1...6}_conv1, block4_conv2</i>) in the form of the raw activation values of the neurons in these layers. Finally, we feed the output, after between 32 and 64 iterations, of our Neural CA into VGG. Our loss is simply the $L_2$ distance between the activations of these neurons with the NCA input and their activations with the template image. We keep the weights of VGG frozen, and use ADAM <d-cite key="adam"></d-cite> to update the weights of the NCA.</p>
<h4>Dataset: </h4>
<p>The template images for this dataset are from the Oxford Describable Textures Dataset <d-cite key="dtd"></d-cite>.  The aim of this dataset was to provide a training and testing set for algorithms to recognize textures and to describe textures using words. The textures were collected to match 47 &quot;attributes&quot; - such as &quot;bumpy&quot; or &quot;polka-dotted&quot;. These 47 attributes were in turn distilled from a set of common words used to describe textures identified by Bhusan, Rao and Lohse <d-cite key="bhusan"></d-cite>. </p>
<h4>Results:</h4>
<p>After a few iterations of training with the above picture as a template, we see the NCA converges to a solution. The very first thing to notice is that the resulting solution found in the NCA parameters is <strong>not</strong> time-invariant - in other words - it&#39;s constantly changing! </p>

<p>This is not completely unexpected. In <i>Differentiable Parametrizations</i>, the authors noted that the images produced when backpropagating into the images space would end up different every time the algorithm was run, due to the stochastic nature of the parametrizations. In our model, we find that we attain such alignment in the temporal dimension, without optimizing for it - a welcome surprise. We believe the reason is twofold. First, we apply our loss after a random number of iterations of the NCA - this means that at any given time step the pattern must be in a state that minimizes the loss. Secondly, the stochastic updates, local communication and quantization all limit and regularize the magnitude of updates at each iteration, meaning the absolute difference between one iteration and the next is often not drastic. We hypothesize that these two properties encourage the NCA to find a solution where each iteration is <strong>aligned</strong> with the previous iteration and thus the motion, or appearance of motion, we see in the trained NCA is the NCA traversing this manifold of locally aligned solutions. </p>

<p>We believe that finding temporally aligned solutions is equivalent to finding an algorithm, or process, that generates the template pattern. Below we demonstrate some exciting behaviours observed when training the NCA on different template images.  </p>

<p></p>
<figure>
<video src='videos/grid.mov' autoplay loop muted style='width: 450px'></video>
<figcaption>An NCA trained to create a pattern in the style of <b>chequered_0121.jpg</b>.</figcaption>
</figure>

<p>Here, we see that the NCA is trained using a template image of a simple black and white grid. </p>
<p>We notice that: </p>

<ul><li>Initially, a non-aligned grid of black and white quadrilaterals is formed. </li>
<li>As time progresses, the quadrilaterals seemingly grow or shrink in both $\vec{x}$ and $\vec{y}$ to more closely approximate squares. Quadrilaterals of both colours either emerge or disappear. Both of these behaviours seem to be an attempt to find local consistency. </li>
<li>After a longer time, the grid often ends up in perfect consistency.</li></ul>

<p>Such behaviour is not entirely unlike what one would expect in a hand-engineered algorithm to produce a consistent grid with local communication.</p>

<p></p>
<figure>
<video src='videos/bubbles.mov' autoplay loop muted style='width: 450px'></video>
<figcaption>An NCA trained to create a pattern in the style of <b>bubbly0101.jpg</b>.</figcaption>
</figure>

<p>In this video, the NCA has learned to reproduce a texture based off a template of clear bubbles on a blue background. One of the most interesting behaviours we observe is that the density of bubbles remains fairly constant. If we re-initialize the grid states, or interactively destroy states, we see a multitude of bubbles &quot;forming&quot;. However - as soon as two bubbles get too close to each other, one of them will spontaneously collapse and disappear, ensuring a constant density. We regard these bubbles as &quot;<a href='#solitons'>solitons</a>&quot; in the solution space of our NCA - a concept we will discuss and investigate at length in a bit.</p>

<p>If we speed the animation up, we see that different bubbles move at different speeds, yet they never collide or touch each other. Simultaneously, they are self-correcting - a damaged bubble will re-grow.</p>

<p>This behaviour is remarkable because it&#39;s behaviour that&#39;s spontaneously arisen without any external loss or auxiliary loss. All of these properties are learned from a combination of the template image, the information stored in the layers of VGG and the inductive bias of the NCA. The NCA has found a rule that effectively approximates many of the properties we expect of bubbles we see in this image - effectively it has learned a process that generates this pattern of bubbles in a robust and &quot;realistic&quot; way.</p>

<p></p>
<figure>
<video src='videos/viking.mov' autoplay loop muted style='width: 450px'></video>
<figcaption>An NCA trained to create a pattern in the style of <b>interlaced_0172.jpg</b>.</figcaption>
</figure>

<p>Here we see one of the authors&#39; favourite patterns - a simple geometric &quot;weave&quot;. Again, we notice the NCA seems to have learned an algorithm for producing this pattern. Each &quot;thread&quot; alternatively joins or detaches from other threads in order to produce the final pattern. This is strikingly similar to what one would attempt to implement in the case of being asked to programmatically generate the above pattern - some algorithm to stochastically weave threads together.</p>



<figure>
<video src='videos/lines.mov' autoplay loop muted style='width: 450px'></video>
<figcaption>An NCA trained to create a pattern in the style of <b>banded_0037.jpg</b>.</figcaption>
</figure>

<p>This NCA also exhibits an algorithm for solving consistency in a striped pattern. The seams in ill-fitting stripes travel up, or down, the stripe, until either they merge to form a single straight stripe, or a stripe shrinks and disappears. Were this to be implemented algorithmically with local communication, it&#39;s not infeasible that a similar algorithm for finding consistency among the stripes would be used.</p>
<h3>Related work </h3>
<p>Pattern generation is by no means a novel field. There has been extensive work predating deep-learning. As briefly touched upon, the inspiration for much of the work came from Turing&#39;s work on pattern generation through local interaction, and later papers based on this principle. However, we also wish to acknowledge some works that we feel have kinship with ours. </p>
<h4>Interactive Evolution of Camouflage</h4>
<p>In Interactive Evolution of Camouflage <d-cite key="ieoc_reynolds"></d-cite>, Craig Reynolds uses a texture description language, consisting of generators and operators, to parametrize a texture patch, which is presented to human viewers who have to decide which patches are the worst at &quot;camouflaging&quot; themselves against a chosen background texture. The population is updated in an evolutionary fashion to maximize &quot;camouflage&quot;, resulting in a texture exhibiting the most camouflage (to human eyes) after a number of iterations. We see strong parallels to our work - instead of a texture generation language, we have an NCA parametrize the texture, and instead of human reviewers we use VGG as an evaluator of the quality of a generated pattern. We believe a fundamental difference lies in the solution space of an NCA. A texture generation language comes with a number of inductive biases and learns a deterministic mapping from coordinate to colour. Our method appears to learn more general algorithms and behaviours giving rise to the target pattern.</p>

<h2 id='feature-visualization'>Feature Visualization</h2>

<p></p>
<figure>
<img src='images/butterfly_eye.jpg' style='width: 450px'></img>
<figcaption>A butterfly with an "eye-spot" on the wings.</figcaption>
</figure>

<p>We&#39;ve now explored some of the fascinating behaviours learned by the NCA when presented with a template image. What if we want to see them learn even more &quot;unconstrained&quot; behaviour? </p>

<p>Some butterflies have remarkably lifelike eyes on their wings. It&#39;s unlikely the butterflies are even aware of this incredible artwork on their own bodies. Evolution placed these there to trigger a response of fear in potential predators. It is likely that neither the predator nor the butterfly has a concept for what an eye is or what an eye does, or even less so any <a href='https://en.wikipedia.org/wiki/Theory_of_mind'>theory of mind</a> regarding the consciousness of the other, but evolutionary development has nonetheless reached a state where the butterfly ingeniously tricks predators into fearing a harmless bug instead of consuming it. </p>

<p>Even more remarkable is the fact that the individual cells composing the butterfly's wings can self assemble into coherent, beautiful, shapes far larger than an individual cell - indeed a cell is on the order of $1^{-5}m$ <d-cite key="Ohno2015-uj"></d-cite> while the features on the wings will grow to as large as $1^{-3}m$ <d-cite key="Iwata2016-mw"></d-cite>. Communication over this distance implies a self-organization over a distance of hundreds or thousands of cells to generate a coherent image of an eye that evolved simply to act as a visual stimuli for an entirely different species. Of course, this pales in comparison to the morphogenesis that occurs in animal and plant bodies, where structures consisting of millions of cells will specialize and coordinate to generate the target morphology. </p>

<p>A common approach to investigating neural networks is to look at what inhibits or excites individual neurons in a network <d-cite key="openai-microscope"></d-cite>. Just as neuroscientists and biologists have often treated cells and cell structures and neurons as black-box models to be investigated, measured and reverse-engineered, there is a large contemporary body of work on doing the same with neural networks. </p>

<p>We can explore this idea with minimal effort by taking our VGG implementation from when we explored pattern generation, and exploring what happens if we task the NCA to enter a state that excites a given neuron in VGG. One of the common resulting NCAs we notice is eye and eye-related shapes - such as the video below - likely as a result of having to detect various animals in ImageNet. Much like the cells forming the eyes on the wings of butterflies to excite certain neurons in the brains of predators, our NCA has learned to have cells collaborate to produce a pattern exciting certain neurons in an arbitrary external neural network.</p>

<p></p>
<figure>
<video src='videos/eyes_vgg.mov' autoplay loop muted style='width: 450px'></video>
<figcaption>An NCA trained to excite <b>mixed4a_472</b> in VGG.</figcaption>
</figure>

<h3>Experiment: Feature Visualization</h3>
<h4>Model: </h4>
<p>We use a model identical to the one used for exploring pattern generation. </p>
<h4>Loss function: </h4>
<p>We use VGG, as before. Our loss maximizes the activations of the chosen neurons in VGG, when evaluated on the output of the NCA. We add an auxiliary loss to encourage the outputs of the NCA to be $\in [0,1]$, as this is not inherently built into th model. We keep the weights of VGG frozen, and use ADAM <d-cite key="adam"></d-cite> to update the weights of the NCA.</p>
<h4>Dataset: </h4>
<p>There is no explicit dataset for this task. VGG is trained on ImageNet. The layers and neurons we chose to excite are sampled qualitatively from OpenAI Microscope.</p>
<h4>Results:</h4>
<p>Similar to the pattern generation experiment, we see quick convergence and a tendency to find temporally dynamic solutions - i.e. most resulting NCAs don&#39;t stay still.</p>

<h3>Interesting behaviours of inception solitons</h3>
<p></p>
<figure>
<video src='videos/eyes.mov' autoplay loop muted style='width: 450px'></video>
<figcaption>An NCA trained to excite <b>mixed4c_439</b> in VGG.</figcaption>
</figure>
<p>Solitons in the form of regular circle-like shapes with internal structure are quite commonly observed in the inception renderings. Two solitons approaching each other too closely may cause one of both of them to decay. We also observe that solitons can "divide" into two complete new solitons.</p>
<p></p>
<figure>
<video src='videos/moving_thread.mov' autoplay loop muted style='width: 450px'></video>
<figcaption>An NCA trained to excite <b>mixed4b_454</b> in VGG.</figcaption>
</figure>
<p>In textures that are composed of threads or lines, or in certain excitations of VGG neurons where the resulting NCA has a &quot;thread-like&quot; quality, the threads grow in their respective directions and will join other threads, or grow around them, as required. This behaviour is similar to the regular lines observed in the striped patterns during pattern generation.</p>


<h3>Robustness</h3>
<p>We encode local information flowing the NCA using the fixed laplacian and gradient filters. As luck would have it, these can be defined for most underlying manifolds - giving us a way of placing our cells on various surfaces, in various configurations, without having to modify the learned model. Suppose we want our cells to live in a hexagonal world. We can redefine our kernels as follows:</p>

<p>Our model, trained in a purely square environment, works out of the box! Play the corresponding setting in the demo to experiment with this. </p>

<p> </p>
<h3>An Aside: Solitons and Lenia</h3>
<p>The motion of waves propagating through a medium can be described using the "classical" wave equation. The below equation defines the change of some quantity $u$ (be it the surface height map of a body of water, the position of a vibrating string, etc.) with respect to the laplacian of $u$. $c$ ends up being the propagation speed of the wave.</p>

<figure>
<p>$\ddot u &#x3D; c^2 \nabla^2 u$2</p>
</figure>

<p>One can imagine waves to come either as a sing]le wave, or as a larger mixture of waves of different frequencies - a phenomenon referred to as a "group" or a "packet". Physical phenomena, however, are rarely as structured and regular as we would like them to be. To describe real-world waves, such as waves in water, light waves propagating, or sound, we have somewhat more complex partial differential equations governing their motion. These waves all share a common property - that waves of different frequencies will travel at different speeds. "Speed" in such a context is a tricky thing to define - however in this case we are referring to the speed of any single given wave - how fast its peak travels in space. In the above, classic, wave equation this corresponds to $c$. However, in the real world, when waves of different frequencies have different speeds, groups of waves are no longer cohesive and will experience "dispersion" - the envelope of the group of waves will change shape over time and potentially not remain cohesive. Even in wave groups with dispersive properties, it is possible to find solutions to their partial differential equations where nonlinearities in the propagation and interaction between waves will counteract the dispersive properties of the wave group. This phenomenon, while lacking a strict definition, is called a "soliton" - as it describes a wave packet which exactly retains its shape during propagation.</p>

<p>Recall the idea briefly touched upon in Growing Neural Cellular Automata - that the communicating grid of CAs can be thought of as a finite difference approximation of a partial differential equation in both time and space, with the equation parametrized by a neural network. Several of the patterns we render in the pattern-generation experiment, as well as in  the inception experiment, consist of well defined structures such as circles or polygons. We consider such structures to be functionally equivalent to solitons and refer to them as such. Such a classification is inspired by solitons referred to in "Lenia" by B. Chan - solid, self-maintaining structures occurring as solutions to the continuous approximation to Game of Life.</p>
<h2 id='hidden-states'>Hidden states</h2>
<p>When biological cells communicate with each other, they do so through a multitude of available communication channels. Cells can emit or absorb different ions and proteins, sense physical motion or "stiffness" of other cells or even emit different chemical signals to diffuse over the local substrate. </p>

<p>There are various ways to visualize communication channels in real cells. One of them is to add to cells a potential-activated dye - allowing a clear picture of the voltage potential the cell is under with respect to the surrounding substrate. This technique has provided useful insight into the communication patterns within groups of cells - showing both local and nonlocal communication over a variety of time-scales.</p>

<p>As luck would have it - we can do something very similar with our Cellular Automata. Recall that our CA model consists of three visible channels, with the rest being treated as latent channels visible to the update step but excluded from any loss function. The video below visualizes the magnitudes of these hidden channels when mapped to intensity in RGB, for an inception NCA. Recall that hidden channels can be considered to be "floating" (to borrow a term from circuit theory) - they are not being pulled to any specific final state or intermediate state by the loss and instead converge to some form a dynamical system assisting the cell fulfill its "true" objective. This means there is no pre-defined assignment of different roles or meaning to different hidden channels, and there is almost certainly redundancy and correlation between different hidden channels. Such correlation may not be visible when applying an arbitrary grouping of channels in order to visualize them in RGB. However, even this simple analysis yields some interesting insights.</p>

<p>	</p>
<figure>
<video src='videos/threads_hidden.mov' autoplay loop muted style='width: 450px'></video>
<figcaption>An NCA trained to excite <b>mixed4b_70</b> in VGG.</figcaption>
</figure>

<p>The fourth quadrant above shows the RGB values of the NCA in the same way as we have been observing it before. The other three quadrants are visualizations of the hidden states. We can use this visualization technique to attempt some rudimentary qualitative analysis of what the NCA may be using the hidden channels for. For instance, in the third quadrant, we see a pattern very similarly to the visible channels. However, the &quot;threads&quot; pointing in each diagonal direction have different colours - one diagonal is an off-pink and the other is a yellow-ish colour. This suggests that one of the things encoded into the hidden states is the direction of a &quot;thread&quot;, likely to allow cells that are inside one of these threads to keep track of which direction the thread is growing, or moving, in. </p>

<p>Analysis of these hidden states is somewhat of a dark art and it is not always possible to draw rigorous conclusions about their role or behaviour. We welcome future work in this direction, as we believe qualitative analysis of these behaviours will be useful for understanding more complex behaviours of CAs.</p>
<h2 id='conclusion'>Conclusion</h2>
<p>Using NCAs as differentiable renderers, with certain style templates, or neuronal excitations as targets produces some very compelling results as well as very interesting and unexpected behaviour. Many of the solutions for generating certain patterns in an image appear similar to the underlying model or physical behaviour producing the pattern - the NCA seems to have inductive bias for treating &quot;objects&quot; in the pattern as individual objects (bubbles, for instance), letting them move freely across the space. The authors theorize that the NCA is forced to find algorithms that can produce such a pattern with purely local interaction. This constraint seems to result in an algorithm to ensure consistency and robustness at a higher level.</p>


</d-article>
<d-appendix>

    <d-footnote-list></d-footnote-list>
    <d-citation-list></d-citation-list>
<d-appendix>